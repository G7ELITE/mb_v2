INFO:     Will watch for changes in these directories: ['/home/devbael/mb-v2']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [26832] using StatReload
/home/devbael/mb-v2/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field "model_id" has conflict with protected namespace "model_".

You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.
  warnings.warn(
INFO:     Started server process [26834]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     127.0.0.1:38430 - "GET /health HTTP/1.1" 200 OK
INFO:     127.0.0.1:44398 - "GET /api/rag/simulate/stream?message=ele%20opera%20com%20sinais%20todo%20dia&safe_mode=true HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: 0b47a4c9, executando busca
Cached resultado para tÃ³pico: 0b47a4c9
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
WARNING:  StatReload detected changes in 'app/core/rag_service.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [26834]
/home/devbael/mb-v2/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field "model_id" has conflict with protected namespace "model_".

You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.
  warnings.warn(
INFO:     Started server process [27782]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
WARNING:  StatReload detected changes in 'app/core/rag_service.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [27782]
/home/devbael/mb-v2/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field "model_id" has conflict with protected namespace "model_".

You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.
  warnings.warn(
INFO:     Started server process [27910]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/prompt HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/models HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/presets HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/knowledge-base HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/prompt HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/presets HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/models HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/knowledge-base HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/leads?page=1&page_size=50&sort_by=created_at&sort_dir=desc&mock=false HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/prompt HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/models HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/presets HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/knowledge-base HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/prompt HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/models HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/presets HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/knowledge-base HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/models HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/prompt HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/knowledge-base HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/presets HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/models HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/prompt HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/knowledge-base HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/presets HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
Lead RAG deletado: ID 1
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "DELETE /api/rag/leads/1 HTTP/1.1" 200 OK
Lead RAG criado: lead 2 (ID: 1)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/leads HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=Ele+usa+sinais+para+otc&safe_mode=true HTTP/1.1" 200 OK
ğŸ¯ Nenhum lead selecionado, usando 'Primeira interaÃ§Ã£o'
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: otc, executando busca
Cached resultado para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=1.0
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
ğŸ”„ ComparaÃ§Ã£o semÃ¢ntica HABILITADA - verificando automaÃ§Ãµes...
ğŸ“‹ Nenhuma automaÃ§Ã£o melhor encontrada, usando resposta da IA
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=mas+usa+sinais+de+forma+automatica%3F&safe_mode=true HTTP/1.1" 200 OK
ğŸ¯ Nenhum lead selecionado, usando 'Primeira interaÃ§Ã£o'
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: ed71e06e, executando busca
Cached resultado para tÃ³pico: ed71e06e
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=1.0
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
ğŸ”„ ComparaÃ§Ã£o semÃ¢ntica HABILITADA - verificando automaÃ§Ãµes...
ğŸ“‹ Nenhuma automaÃ§Ã£o melhor encontrada, usando resposta da IA
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: ed71e06e
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
Placeholders desconhecidos no prompt: ['mensagem_atual', 'historico_mensagens']
Prompt RAG personalizado salvo: 706 caracteres
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "PUT /api/rag/prompt HTTP/1.1" 200 OK
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (0 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: d15c537c, executando busca
Cached resultado para tÃ³pico: d15c537c
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=1.0
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=mas+usa+sinais+de+forma+automatica+ou+nao%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
ğŸ”„ ComparaÃ§Ã£o semÃ¢ntica HABILITADA - verificando automaÃ§Ãµes...
ğŸ“‹ Nenhuma automaÃ§Ã£o melhor encontrada, usando resposta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: d15c537c
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (4 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: 40771a08, executando busca
Cached resultado para tÃ³pico: 40771a08
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=1.0
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=usa+sinais+de+forma+automatica+ou+nao%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: 40771a08
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (8 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: c96b837d, executando busca
Cached resultado para tÃ³pico: c96b837d
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=1.0
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=meu+nome+%C3%A9+gabriel&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 34 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: c96b837d
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (12 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: ce242ba7, executando busca
Cached resultado para tÃ³pico: ce242ba7
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=usa+sinais+manual+pra+operar%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: ce242ba7
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=qual+%C3%A9+o+meu+nome%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (16 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: 4f3a43d4, executando busca
Cached resultado para tÃ³pico: 4f3a43d4
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 12 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: 4f3a43d4
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (20 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: otc, executando busca
Cached resultado para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=ele+usa+sinais+manuais+em+otc+na+segunda-feira%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (24 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=usa+otc+na+segunda-feira%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
Placeholders desconhecidos no prompt: ['mensagem_atual', 'historico_mensagens']
Prompt RAG personalizado salvo: 531 caracteres
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "PUT /api/rag/prompt HTTP/1.1" 200 OK
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (28 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: otc, executando busca
Cached resultado para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=usa+otc+na+segunda-feira%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
Placeholders desconhecidos no prompt: ['mensagem_atual', 'historico_mensagens']
Prompt RAG personalizado salvo: 486 caracteres
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "PUT /api/rag/prompt HTTP/1.1" 200 OK
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (32 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: otc, executando busca
Cached resultado para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=usa+otc+na+segunda-feira%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (36 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: a6dfea7a, executando busca
Cached resultado para tÃ³pico: a6dfea7a
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+segunda-feira%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: a6dfea7a
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 59 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (40 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: a6dfea7a
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.8, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+segunda-feira%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: a6dfea7a
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 60 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Usando histÃ³rico REAL do lead 'lead 2' (44 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: 069b4519, executando busca
Cached resultado para tÃ³pico: 069b4519
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.8, max_tokens=400, top_p=1.0
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+segunda%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 54 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: 069b4519
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
Lead RAG deletado: ID 1
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "DELETE /api/rag/leads/1 HTTP/1.1" 200 OK
Lead RAG criado: antoin (ID: 1)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/leads HTTP/1.1" 200 OK
ğŸ¯ Nenhum lead selecionado, usando 'Primeira interaÃ§Ã£o'
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: 069b4519
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.8, max_tokens=400, top_p=1.0
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+segunda%3F&safe_mode=true HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 83 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: 069b4519
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Nenhum lead selecionado, usando 'Primeira interaÃ§Ã£o'
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: 069b4519, executando busca
Cached resultado para tÃ³pico: 069b4519
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=1.0
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+segunda%3F&safe_mode=true HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 57 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: 069b4519
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Nenhum lead selecionado, usando 'Primeira interaÃ§Ã£o'
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: 069b4519
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+segunda%3F&safe_mode=true HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 59 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: 069b4519
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Nenhum lead selecionado, usando 'Primeira interaÃ§Ã£o'
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: otc, executando busca
Cached resultado para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+domingo+no+mercado+fora+de+OTC%3F&safe_mode=true HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 81 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Nenhum lead selecionado, usando 'Primeira interaÃ§Ã£o'
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: otc, executando busca
Cached resultado para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+domingo+no+mercado+fora+de+OTC%3F&safe_mode=true HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 44 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
Placeholders desconhecidos no prompt: ['mensagem_atual', 'historico_mensagens']
Prompt RAG personalizado salvo: 706 caracteres
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "PUT /api/rag/prompt HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+domingo+no+mercado+fora+de+OTC%3F&safe_mode=true HTTP/1.1" 200 OK
ğŸ¯ Nenhum lead selecionado, usando 'Primeira interaÃ§Ã£o'
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Nenhum lead selecionado, usando 'Primeira interaÃ§Ã£o'
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: otc, executando busca
Cached resultado para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=0.3, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+sabado+no+mercado+fora+de+OTC%3F&safe_mode=true HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Nenhum lead selecionado, usando 'Primeira interaÃ§Ã£o'
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=1.0, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+sabado+no+mercado+fora+de+OTC%3F&safe_mode=true HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
ğŸ¯ Usando histÃ³rico REAL do lead 'antoin' (0 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: otc, executando busca
Cached resultado para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=1.0, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+sabado+no+mercado+fora+de+OTC%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 50 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
Placeholders desconhecidos no prompt: ['mensagem_atual', 'historico_mensagens']
Prompt RAG personalizado salvo: 428 caracteres
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "PUT /api/rag/prompt HTTP/1.1" 200 OK
ğŸ¯ Usando histÃ³rico REAL do lead 'antoin' (4 mensagens)
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache miss para tÃ³pico: otc, executando busca
Cached resultado para tÃ³pico: otc
ğŸ¯ Usando prompt personalizado da interface (100% controlado pelo usuÃ¡rio)
ğŸ“ Prompt formatado com 1 linhas de histÃ³rico
ğŸš€ FAZENDO CHAMADA REAL PARA OPENAI - Modelo: gpt-4o
âš™ï¸ ParÃ¢metros: temp=1.0, max_tokens=400, top_p=0.5
ğŸ¯ Embedding Model: text-embedding-3-large (para RAG)
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/simulate/stream?message=opera+sabado+no+mercado+fora+de+OTC%3F&safe_mode=true&lead_id=1 HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… RESPOSTA REAL RECEBIDA: 54 caracteres
â­ï¸ ComparaÃ§Ã£o semÃ¢ntica DESABILITADA - usando resposta direta da IA
ğŸ“ HistÃ³rico REAL atualizado para lead 1: +2 mensagens
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "POST /api/rag/simulate HTTP/1.1" 200 OK
ğŸ“‹ Parser FAQ: 13 seÃ§Ãµes de perguntas/respostas criadas
KB carregada: 13 seÃ§Ãµes
Cache hit para tÃ³pico: otc
INFO:     2804:1054:4018:caf0:fdf6:c62a:e97c:203b:0 - "GET /api/rag/leads HTTP/1.1" 200 OK
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
